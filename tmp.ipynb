{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629a9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.models import EEGNet\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from mne.decoding import CSP\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "sample_file = \"/var/datasets/physionet.org/files/MI/files/eegmmidb/1.0.0/S001/S001R03.edf\"\n",
    "\n",
    "def load_data(file_path, tmin=-1, tmax=5):\n",
    "    import mne\n",
    "    import numpy as np\n",
    "\n",
    "    # --- carica il file EDF ---\n",
    "    raw = mne.io.read_raw_edf(file_path, preload=True, stim_channel='Event marker', verbose=False)\n",
    "    sfreq = raw.info['sfreq']\n",
    "\n",
    "    # --- filtra i dati ---\n",
    "    raw.filter(1., 40., fir_design='firwin', verbose=False)\n",
    "\n",
    "    # --- estrai gli eventi ---\n",
    "    events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
    "\n",
    "    print(f\"Event IDs found: {event_id}\")\n",
    "    print(f\"events: {events}\")\n",
    "\n",
    "\n",
    "\n",
    "    # --- crea gli epochs ---\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True, verbose=False)\n",
    "\n",
    "    # --- mappa le etichette ---\n",
    "    if 'T0' in event_id and 'T1' in event_id and 'T2' in event_id:\n",
    "        # left hand vs right hand\n",
    "        label_map = {'T0': 0, 'T1': 1, 'T2': 2}\n",
    "    elif 'T3' in event_id and 'T4' in event_id:\n",
    "        # both hands vs both feet\n",
    "        label_map = {'T3': 4, 'T4': 5}\n",
    "    elif 'T0' in event_id and 'T1' in event_id and 'T2' in event_id:\n",
    "        # left hand vs right hand vs feet\n",
    "        label_map = {'T0': 0, 'T1': 1, 'T2': 2}\n",
    "    else:\n",
    "        return None, None\n",
    "    # --- estrai i dati per ogni tipo di evento ---\n",
    "    data = []\n",
    "    labels = []\n",
    "    for code, label in label_map.items():\n",
    "        if code in epochs.event_id:  # controlla che esista\n",
    "            ep_data = epochs[code].get_data()  # (n_epochs, n_channels, n_times)\n",
    "            # check if the n_times is 161\n",
    "            if ep_data.shape[2] != int((tmax - tmin) * sfreq) + 1 or sfreq != 160:\n",
    "                print(f\"Skipping {file_path} due to unexpected n_times: {ep_data.shape[2]}\")\n",
    "                continue\n",
    "            data.append(ep_data)\n",
    "            labels.extend([label] * len(ep_data))\n",
    "    return np.concatenate(data), np.array(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8da5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inspect_weights(file_path):\n",
    "    # Carica il checkpoint (in CPU per evitare problemi di memoria se non si è su GPU)\n",
    "    checkpoint = torch.load(file_path, map_location=torch.device('cpu'))\n",
    "\n",
    "    if 'model_state_dict' not in checkpoint:\n",
    "        print(\"Errore: La chiave 'model_state_dict' non è stata trovata nel file.\")\n",
    "        return\n",
    "\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    print(f\"Ispezione dei pesi del modello nel file: {file_path}\\n\")\n",
    "\n",
    "    # Stampa le shape di ogni tensore salvato\n",
    "    for name, tensor in state_dict.items():\n",
    "        # I tensori del backbone Cbramod avranno nomi lunghi\n",
    "        # I tensori del classifier avranno nomi come 'classifier.0.weight' se è un SimpleFeaturesClassifier\n",
    "        \n",
    "        # Identificazione del componente\n",
    "        if 'feature_extractor' in name:\n",
    "            component = \"BACKBONE (CBraMod)\"\n",
    "        elif 'classifier' in name:\n",
    "            component = \"CLASSIFIER HEAD\"\n",
    "        else:\n",
    "            component = \"ALTRO/DVAE\"\n",
    "\n",
    "        print(f\"[{component:<20}] {name:<60} Shape: {list(tensor.shape)}\")\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "# inspect_weights('/home/burger/canWeReally/experiments/Mode_F_MI_PORCA_MISA_Misaaaa_continue_learning_rrr/last_model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac82cbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ispezione dei pesi del modello nel file: /home/burger/canWeReally/experiments/Mode_F_MI_PORCA_MISA_Misaaaa_continue_learning_rrrrrr/last_model_weights.pt\n",
      "\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.mask_encoding        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.positional_encoding.0.weight Shape: [200, 1, 19, 7]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.positional_encoding.0.bias Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.0.weight     Shape: [25, 1, 1, 49]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.0.bias       Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.1.weight     Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.1.bias       Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.3.weight     Shape: [25, 25, 1, 3]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.3.bias       Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.4.weight     Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.4.bias       Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.6.weight     Shape: [25, 25, 1, 3]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.6.bias       Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.7.weight     Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.proj_in.7.bias       Shape: [25]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.spectral_proj.weight Shape: [200, 101]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.patch_embedding.spectral_proj.bias   Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.0.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.1.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.2.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.3.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.4.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.5.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.6.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.7.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.8.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.linear1.weight      Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.linear1.bias        Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.linear2.weight      Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.linear2.bias        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.norm1.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.norm1.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.norm2.weight        Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.9.norm2.bias          Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.linear1.weight     Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.linear1.bias       Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.linear2.weight     Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.linear2.bias       Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.norm1.weight       Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.norm1.bias         Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.norm2.weight       Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.10.norm2.bias         Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.self_attn_s.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.self_attn_s.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.self_attn_s.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.self_attn_s.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.self_attn_t.in_proj_weight Shape: [300, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.self_attn_t.in_proj_bias Shape: [300]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.self_attn_t.out_proj.weight Shape: [100, 100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.self_attn_t.out_proj.bias Shape: [100]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.linear1.weight     Shape: [800, 200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.linear1.bias       Shape: [800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.linear2.weight     Shape: [200, 800]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.linear2.bias       Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.norm1.weight       Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.norm1.bias         Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.norm2.weight       Shape: [200]\n",
      "[BACKBONE (CBraMod)  ] feature_extractor.model.encoder.layers.11.norm2.bias         Shape: [200]\n",
      "[CLASSIFIER HEAD     ] classifier.head.3.weight                                     Shape: [4, 200]\n",
      "[CLASSIFIER HEAD     ] classifier.head.3.bias                                       Shape: [4]\n"
     ]
    }
   ],
   "source": [
    "path_to_weights = '/home/burger/canWeReally/experiments/Mode_F_MI_PORCA_MISA_Misaaaa_continue_learning_rrrrrr/last_model_weights.pt'\n",
    "inspect_weights(path_to_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d194abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event IDs found: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n",
      "events: [[    0     0     1]\n",
      " [  672     0     3]\n",
      " [ 1328     0     1]\n",
      " [ 2000     0     2]\n",
      " [ 2656     0     1]\n",
      " [ 3328     0     2]\n",
      " [ 3984     0     1]\n",
      " [ 4656     0     3]\n",
      " [ 5312     0     1]\n",
      " [ 5984     0     3]\n",
      " [ 6640     0     1]\n",
      " [ 7312     0     2]\n",
      " [ 7968     0     1]\n",
      " [ 8640     0     2]\n",
      " [ 9296     0     1]\n",
      " [ 9968     0     3]\n",
      " [10624     0     1]\n",
      " [11296     0     2]\n",
      " [11952     0     1]\n",
      " [12624     0     3]\n",
      " [13280     0     1]\n",
      " [13952     0     3]\n",
      " [14608     0     1]\n",
      " [15280     0     2]\n",
      " [15936     0     1]\n",
      " [16608     0     2]\n",
      " [17264     0     1]\n",
      " [17936     0     3]\n",
      " [18592     0     1]\n",
      " [19264     0     2]]\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(sample_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weCannot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
